\section{Discussion and Summary} \label{sec:discussionsummary}

Recently implementations of action DF - based modelling of 6D data in the Galactic disk have been put forth, in part to lay the ground-work fo Gaia.
[Binney,Sanders,Piffl,Bovy,Rix,McMillan??].
%\bibitem[McMillan \& Binney(2013)]{2013MNRAS.433.1411M} McMillan, P.~J., \& Binney, J.~J.\ 2013, \mnras, 433, 1411 ].
 We present \RM, an improved implementation of the dynamical modelling machinery by \citet{bov13}, to recover the potential and orbit distribution function of stellar \MAPs within the Galactic disk. In this work we investigated the capabilities, strengths and weaknesses of \RM by testing its robustness against the breakdown of some of its assumptions - for well defined, isolated test cases using mock data. Overall the method works very well and reliable, also if there are small deviations of the model assumptions from the real world galaxy.

\subsection{Improved Computational Speed for Application to Larger Data Sets}

\RM applies a full likelihood analysis and is statistically well-behaved. It allows for a straightforward implementation of different potential model families and a flexible number of free fit parameters in potential and qDF. It also accounts for selection effects by using full 3D selection functions (given some symmetries). \RM is an asymptotically normal, un-biased estimator and the precision of parameter recovery increases by $1/\sqrt{N}$ with the number of stars.\\

Large data sets in the age of Gaia require more, and more accurate, likelihood evaluations for more flexible models. To be able to deal with these increased computational demands and explore larger parameter spaces, we sped up the code by combining a nested grid approach with MCMC and by faster action calculation using the St\"{a}ckel \citep{bin12} interpolation grid by \citet{bov15}. Especially accurately determining the likelihood normalisation will be of crucial importance for large data sets. The nested-grid approach automatizes the search for the optimal normalisation integration ranges ("fiducial qDF") and start position for the MCMC walkers, which helps the MCMC to converge fast and to reduce biases due to insufficient accuracy. However, application of \RM to millions of stars simultaneously with acceptable accuracy will still be a task for supercomputers and calls for even more improvements and speed-up in the fitting machinery.

\subsection{Modelling Sensitivity to Properties and Unaccounted Imperfections of the Data Set}

\paragraph{Choice of observation volume.} We found that the \emph{position} of the survey volume maters little, in the sense that there are no regions in the Galaxy that contain intrinsically stars on manifestly more diagnostic orbits than others. Closer to the disk and at smaller Galactocentric radii it is only the increased number of stars that will lead to tighter constraints. Concerning the \emph{shape} of the survey volume, a large radial \emph{and} vertical coverage is best. In the axisymmetric case phi coverage doesn't matter. Making a volume cut for stars, that lie around $R_\odot$ but at larger $phi$, could therefore improve the results, if their measurements are very uncertain.
\\\MAPs of different scale length and temperature probe different regions of the Galaxy \citep{bov13}. But there is no easy rule of thumb for which survey volume and stellar population which potential and DF parameter is constrained best.

\paragraph{Selection function misjudgment.} Surprisingly \RM seems to be very robust against misjudgments in the selection function of the data. The reason for this robustness could be, that missing stars in the data set do not affect the connection between a star's velocity and position, which is given by the potential. A lot of information about the potential profile is stored in the rotation curve - but even when not including measurements of tangential velocities in the analysis, small misjudgments of the incompleteness do not affect the potential recovery.
\\That we reproduce the qDF equally well, could be due to the symmetry of our assumed incompleteness profiles around the sun. We investigated a decrease in knowledge of the data completeness in distance from the sun and Galactic plane. Our test with the radial incompleteness profile could be understood as a decreasing detection rate due to the lower apparent brightness of stars at larger distances. The test with the planar incompleteness profile could mimic a misjudgment of the dust obscuration within the Galactic plane. Both effects would show the same symmetries as tested in this work. 
\\This result is encouraging for future studies, but nevertheless surprising as it was previous believed that knowing the (spatial) selection function very precisely is of large importance for dynamical modelling \citep{rix13}.

\paragraph{Measurement errors.} Properly convolving the likelihood with measurement errors is computational very expensive. By ignoring positional errors and only including distance errors as part of the velocity error, we can drastically reduce the computational costs. [TO DO - No definite result after this disclaimer:] For stars within 3 kpc from the sun this approximation works well for distance errors of $\sim 10\%$ or smaller. The number of MC samples needed for the error convolution using MC integration scales by $N_\text{error} \propto (\sigma_{v,\text{max}})^2$ with the maximum velocity error at the edge of the sample. If we misjudge the size of the true measurement errors, we only can reproduce the true model parameters, as long as the velocity errors are smaller than the intrinsic velocity dispersion of the data set.

\subsection{Data Deviations from the Modelling Assumptions about the Distribution Function and the Potential}

\paragraph{Deviations from the qDF Assumption.}  Our modelling is founded on the assumption, that we can identify {\sl a priori} sub-components of the Galactic disk that follow a qDF (e.g. by considering \MAPs ). There are two reasons why any chosen sub-sample of star (here a \MAP ) may not be well described by any qDF. Either, because nature is more complex, or because even if perfect
\MAPs would be well described by qDFs finite abundance errors would mix \MAPs .  We have considered both cases.

 In Example 1 in \S ??? we investigated how well we can recover the potential, if this assumption was not perfectly satisfied, i.e. the \MAPs true DF does not perfectly follow a qDF. We considered two cases: a) a hot DF, that has less stars at small radii and more stars with low velocities than predicted by the qDF (reddish data sets in Fig. \ref{fig:isoSphFlexMix_mockdata}), or b) a cool DF that has broader velocity dispersion wings and less stars at large radii than predicted by the qDF (bluish data sets). We find that case a) would give more reliable results for the potential parameter recovery.
\\If we assumed that the distribution of stars from one \MAP is caused by radial migration away from the initial location of star formation, it would more likely that the qDF overestimates the true number of stars at smaller radii than underestimating it at larger radii. [TO DO: Is this actually a sensible argument???]
\\Following this, focusing the analysis especially on hotter \MAPs could be an advisable way to go in the future, if there is doubt that the stars truly follow the qDF.

 Another critical point is the binning of stars into \MAPs depending on their metallicity and $\alpha$ abundances. Example 2 in \S ??? could be understood as a model scenario for decreasing bin sizes in the metallicity-$\alpha$ plane when sorting stars in different \MAPs, assuming that there is a smooth variation of qDF within the metallicity-$\alpha$ plane and each \MAP indeed follows a qDF. We find that, in the case of 20,000 stars in each bin, differences of $20\%$ in the qDF parameters of two neighbouring bins can still give quite good constraints on the potential parameters. 
\\We compare this with the relative difference in the qDF parameters in the bins in Fig. 6 of \cite{bov13}, which have sizes of $[Fe/H] = 0.1$ dex and $\Delta [\alpha/Fe] = 0.05$ dex. It seems that these bin sizes are large enough to make sure that $\sigma_{R,0}$ and $\sigma_{z,0}$ of neighbouring \MAPs do not differ more than $20\%$. Fig. \ref{fig:isoSphFlexMixCont} and \ref{fig:isoSphFlexMixDiff} suggest that especially the tracer scale length $h_R$ needs to be recovered to get the potential right. For this parameter however the bin sizes in fig. 6 of \cite{bov13} might not yet be small enough to ensure no more than $20\%$ of difference in neighbouring $h_R$. This is especially the case in the low-$\alpha$ ($[\alpha/Fe] \lesssim 0.2$), intermediate-metallicity ($[Fe/H] \sim -0.5$) \MAPs. The above is valid for 20,000 stars per \MAP. In case there are less than 20,000 stars in each bin the constraints are less tight and due to Poisson noise one could also allow larger differences in neighbouring \MAPs while still getting reliable results. [TO DO: Discuss Binney \& Sanders doubts about binning.]

\paragraph{Gravitational Potential beyond the Parameterized Functions Considered.}  In the long run \RM should incorporate a family of gravitational potential models that can reproduce the essential features of the MW's true mass distribution. While our fundamental assumption of the Galaxy's axisymmetry is at odds with the obvious existence of non-axisymmetries in the MW, we will not dive into investigating this implications in the scope of this paper. Instead we test how a misjudgment of the parametric potential form affects the recovery by fitting a potential of St\"{a}ckel form \citep{bat94} to mock data from a different potential family with halo, bulge and exponential disk. The recovery is quite successful and we get the best fit within the limits of the model. However, even a strongly flattened St\"{a}ckel potential component has difficulties to recover the very flattened mass distribution of an exponential disk. This will lead to underestimation of the vertical velocity dispersion at the sun. aA the qDF parameter $\sigma_{z,0}$ corresponds to the physical vertical velocity dispersion at the sun, a comparison with direct measurements could be a valuable cross-checking reference. [TO DO: This might not be true. For isochrone and Staeckel potential I get this behaviour, but not for the MW14-Pot. Might be, because it's not separable.] In case of as many as 20,000 stars we should therefore already be able to distinguish between different potential models.
\\The advantage of using a St\"{a}ckel potential with \RM is firstly the exact and fast action calculation via the numerical evaluation of a single integral, and secondly that the potential has a simple analytic form, which greatly speeds up calculations of forces and frequencies (as compared to potentials in which only the density has an easy description like the exponential disk). A superposition of several simple Kuzmin-Kutuzov St\"{a}ckel components can successfully produce MW-like rotation curves (see \citet{bat94}, \citet{fam03} and Fig. ???) and one could think of adding even more components for more flexibility, e.g. a small roundish component for the bulge.
\\The potential model used by \citet{bov13} had only two free parameters (disk scale lentgh and halo contribution to $v_\text{circ}(R_\odot)$. To circumvent the obvious disadvantage of this being at all not flexible enough, they fitted the potential separately for each \MAP and recovered the mass distribution for each \MAP only at that radius for which it was best constrained - assuming that \MAPs of different scale length would probe different regions of the Galaxy best. Based on our results in Fig. \ref{fig:MW14vsKKS2SphFlex} this seems to be indeed a sensible approach [TO DO: Check that this is indeed the case - it is not clear to me from the plot. ???].
\\We suggest that combining the flexibility and computational advantages of a superposition of several St\"{a}ckel potential components with probing the potential in different regions with different \MAPs as done by \citet{bov13}, could be a promising approach to get the best possible constraints on the MW's potential.

\subsection{Different Modelling Approaches using Action-based Distribution Functions}

We have focussed for the time being on \MAPs for a number of reasons: First, they seem to permit simple DFs \citep{bov12b,bov12c,bov12d}, i.e. approximately qDFs \citep{tin13}. Second, all stars, e.g. those from different \MAPs, must orbit in the same potential. Therefore each \MAP will and can yield quite different DF parameters; but each \MAP will also provide a (statistically) independent estimate of the potential parameters. At the same time -- if all is well -- those potential parameters, derived from different \MAPs, should be mutually consistent. In some sense, this approach focusses on constraining the potential, treating the DF parameters as nuisance parameters.

The main drawback is that we have many astophysical reasons that the DF properties (for reasons of galaxy evolution and chemical evolution) are astrophysically linked between different \MAPs. Ultimately, the goal is to do a fully consistent chemodynamical model that simultaneously fits the potential and $\text{DF}(\vect{J},\text{[X/H]})$ simultaneously (where [X/Fe] denotes the full abundance space) with a full likelihood analysis. 
\\This has not yet been attempted. 

Since the first application of \RM by \citet{bov13} there have been two similar efforts to constrain the Galactic potential and/or orbit distribution using action-based distribution functions:

\citet{pif14} fitted both potential and a $f(\vect{J})$ to giant stars from the RAVE survey \citep{ste06} and the vertical stellar number density profiles in the disk by \citet{jur08}. They did not include any chemical abundances in the modelling. Instead, they used a superposition of action-based DFs to describe the overall stellar distribution at once: a superposition of qDFs [TO DO: CHECK] for cohorts in the thin disk, a single qDF [TO DO: CHECK] for the thick disk stars and an additional DF for the halo stars. Taking proper care of the selection function requires a full likelihood analysis and the calculation of the likelihood normalisation is computational expensive. \citet{pif14} choose to circumvent this problem by directly fitting a) histograms of the three velocity components in eight spatial bins to the velocity distribution predicted by the DF and b) the vertical density profile predicted by the DF to the profiles by \citet{jur08}. The vertical force profile of their best fit mass model nicely agrees with the results from \citet{bov13} for $R>6.6$ kpc. The disadvantage of their approach is, that by binning the stars spatially, a lot of stellar information is not used.

\citet{san15} have focussed on understanding the abundance-dependence of the DF, relying on a fiducial potential. They developed extended distribution functions, i.e. functions of both actions and metallicity for a superposition of thin and thisk disk, each consisting of several cohorts described by qDFs, a DF for the halo, a functional form of the metallicity of the interstellar medium at the time of birth, and a simple prescription for radial migration. They applied a full likelihood analysis accounting for selection effects and found a best fit for the eDF in a fixed fiducial potential by \citet{deh98} to the stellar phase-space and metallicity [TO DO: CHECK] data of the Geneva-Kopenhagen Survey (GS) \citep{2004A&A...418..989N,2009A&A...501..941H} and the stellar density curves by \citet{{gil83}}. Their best fit predicted the velocity distribution of SEGUE G dwarfs quite well, but had biases in the metallicity distribution, which they accounted to being a problem with the SEGUE metallcities. 

\subsection{On the assumption of axisymmetry}

The key assumption in our modelling, as well as in the approaches by \citet{pif14} and \citet{san15} described above, is the overall axisymmetry of Galaxy's potential and DF. This has the convenient advantage, that actions are conserved in axisymmetric potentials and can be calculated straightforward via the "St\"{a}ckel Fudge" by \citet{bin????} and/or a single integration (in the case of separable potentials). Of course the Galactic disk is in reality not axisymmetric and actions are not conserved: Spiral arms in the disk and the Galactic bar lead to angular momentum exchange and therefore radial migration of stars, i.e. the orbit on which the stars were born on are modified \citep{2011A&A...527A.147M,2014MNRAS.443.2757K}. Apart from these obvious non-axisymmetries in the Galaxy, the disk itself is not smooth, as there is lot of sub-structure, streams and moving groups within the disk. A famous example is the Arcturus moving group, for which \citet{2004ApJ...601L..43N} found that the stars might have their origin in a disrupted satellite.
\\Spiral arms, the stirring of the Galactic bar and the disk sub-structure will undoubtedly affect our modelling with \RM. How strong this effect will be and if the modelling can still work, needs to be investigated in detail in future work, e.g. by trying to recover the potential in N-body simulations. But as actions are conserved under adiabatic changes of the potential \citet{bin08}, and the vertical action under radial migration [TO DO: REF], there is some hope, that the modelling could still work.

The ultimate goal would be to theoretically describe those non-axisymmetries and sub-structures in terms of DFs in action/angle-abundance space. We see the current axisymmetric modelling approaches as intermediate step to this goal: \citet{1998AJ....115.2384D} described the disk's overall stellar distribution as a smooth background distribution superimposed with sub-structure; the axisymmetric DFs used and to be found by \RM and similar approaches could be treated as this smooth background. Firstly, this smooth background DF could help to actually find and identify the disk substructure in action space (see e.g. \citet{2010MNRAS.409..145S,2008ApJ...685..261K} for similar approaches to find disk substructure, which then helps to find DF descriptions. Secondly, and because simple superposition of action-based DFs is possible (see e.g. [TO DO: REF (see Payel's hint)]), the substructure DFs could then be directly added to the background DF and incorporated in the modelling. In other words, modelling the Galaxy together with its non-axisymmetries and substructure could be approached as applying perturbations to an axisymmetric equilibrium model. And \RM will help finding this equilibrium model.

Such a Galaxy model will be also important in the meantime: Many studies of Galaxy structure and evolution use orbits as tracers and therefore require a reliable fiducial potentials to turn stellar positions and velocities into orbits. And as long as we are as far away from realistic Galaxy models as we are now, the axisymmetric case well need to be our reference.