\subsection{Fitting Procedure} \label{sec:fitting}

We search the $(p_\Phi,p_\text{DF})$ parameter space for the maximum of the likelihood in eq. (\ref{eq:likelihood}). The most crucial part of our fitting procedure for finding the peak and width of the likelihood in the $(p_\Phi,p_\text{DF})$ parameter space  is therefore the reduction of computational costs while not introducing systematic errors due to numerical inaccuracies. We do this by a two-step procedure: The first step finds the approximate peak and width of the likelihood using a nested-grid search, while the second step will either sample the shape of the likelihood (or rather the posterior probability distribution) using a Monte-Carlo Markov Chain (MCMC) or calculate the likelihood on a much finer grid.

\subsubsection{Fitting Step 1: Finding the likelihood peak with a Nested-grid search}

[TO DO: Make consistent: use of $\sigma_{R,0}$ and $\sigma_R$ as profile or dispersion at sun. ???]

The $(p_\Phi,p_\text{DF})$ parameter space can be high-dimensional and we do not necessarily have a good notion where to look for the likelihood peak initially. We use a nested-grid approach to find the peak and to minimize effectively the number of models for which we have to evaluate the likelihood.\footnote{The nested-grid approach is preferable to other optimizing methods, because it can be effectively parallelized on multiple computer cores, while methods like ??????? work linearly and would therefore take longer.}
\\The nested-grid search works in the following way: 
\begin{itemize}

\item \emph{Initialization.} We set up an initial grid with $3^N$ regular grid points, where $N$ is the number of free model parameters $M$ (cf. \S\ref{kap:modpar}. The range of this initial grid is chosen sufficiently large and should encompass all reasonable\footnote{To get a better feeling where in parameter space the true $p_\text{DF}$ parameters lie, we fit eq. (???) directly to the data. This gives a very good inital guess for $\sigma_{R,0}$ and $\sigma_{z,0}$. To improve the estimate for $h_R$, we fit eq. (???) only to stars within a thin wedge around $(R=0,z=0)$ and then apply the relation in fig. 5 in \citet{bov13} between the stars' measured scale length $h_R^\text{out}$ and the qDF tracer scale length $h_R^\text{in}=h_R$.} values for the parameters. 

\item  \emph{Evaluation.} Then we evaluate the likelihood at each grid-point. Stepping through different $p_\Phi$ parameters is much more computationally expensive than stepping through different DF parameter sets, because of the many $\vect{x},\vect{v} \overset{p_\Phi}{\longrightarrow} \vect{J}$ transformations that have to be performed for each new potential. Evaluation on a grid allows us to have an outer loop that iterates over the potential parameters $p_\Phi$ and pre-calculates the actions and an inner loop which, for a given potential, goes over the qDF parameters $p_\text{DF}$ and uses these pre-calculated actions to evaluate the likelihood (analogously to fig. 9 in \citet{bov13}).
\\Both, the pre-calculation of actions and the likelihood calculations for all $p_\text{DF}$s, can be easily sped up by distributing them over many computer cores.

\item \emph{Iteration.} To find from the very sparse $3^N$ likelihood grid a new and better grid, that is more centered on the likelihood and has a width that, in the optimal case, is of order of the width of the likelihood, we proceed in the following: For each of the model parameters $M$ the likelihood is marginalized over all the other dimensions. From the resulting three grid points, the fraction of second highest and highest likelihood is compared with $e^{-8}$: If the fraction is larger than that, the range of the grid is still larger than a \textasciitilde 4-sigma likelihood environment around the peak. In this case we simply choose the grid point with the highest likelihood as the new grid range. Otherwise, if the width of the grid is already small enough, we can fit a Gaussian to the three grid points and determine a new and better 4-sigma fitting grid range from it, with the best-fit Gaussian mean as the new central grid point. 
\\We proceed with iteratively evaluating the likelihood on finer and finer grids, until we have found a 4-sigma fit range in each of the model parameter dimensions.

\item \emph{The fiducial qDF.} For the above strategy to work properly, the action pre-calculations have to be independent of the choice of qDF parameters. This is clearly the case for the $N_j \times N_\text{error}$ [TO DO: explain $N_\text{error}$ ???]  stellar data actions $\vect{J}_i$. To calculate the normalisation in eq. (\ref{eq:prob}), $N_\text{spatial}^2 \times N_\text{velocity}^3$ actions $\vect{J}_n$ are needed. Formally the spatial coordinates at which the $\vect{J}_n$ are calculated depend on the $p_\text{DF}$ parameters via the integration ranges in eq. (\ref{eq:tracerdensity}). To relax this dependence we instead use the same velocity integration limits in the likelihood calculations for all $p_\text{DF}$s in a given potential. This set of parameters, that sets the velocity integration range globally, $(\sigma_{R,0},\sigma_{z,0},h_{\sigma_R},h_{\sigma_z})$ in eq. (???), is referred to as the "fiducial qDF". Using the same integration range in the density calculation for all qDFs at a given $p_\Phi$ makes the normalisation vary smoothly with different $p_\text{DF}$. Choosing a fiducial qDF that is very off from the true qDF can however lead to large biases. The optimal values for the fiducial qDF are the (yet unknown) best fit $p_\text{DF}$ parameters. We take care of this by setting, in each iteration step of the nested-grid search, the fiducial qDF simply to the $p_\text{DF}$ parameters of the central grid point.  As the nested-grid search approaches the best fit values, the fiducial qDF approaches automatically the optimal values as well. This is another advantage of the nested-grid search, because the result will not be biased by a poor choice of the fiducial qDF.

\item \emph{Speed Limitations.} Overall the computation speed of this nested-grid approach is dominated (in descending order of importance) by a) the complexity of potential and action calculation, b) the number $N_j \times N_\text{error} + N_\text{spatial}^2 \times N_\text{velocity}^3$ of actions to calculate, i.e. the number of stars, error samples and numerical accuracy of the normalisation calculations, c) the number of different potentials to investigate (i.e. the number of free potential parameters and number of grid points in each dimension) and d) the number of qDFs to investigate. The latter is also non-negligible, because for such a large number of actions the number of  qDF-function evaluations also take some time. We therefore restrict the nested grid search to just three points in each dimension of potential and qDF parameters.
\end{itemize}

\subsubsection{Fitting Step 2: Sampling the shape of the likelihood with MCMC}

After the nested-grid search is converged, we already have a very good feeling for where the peak of the likelihood is and how large the approximate 4-sigma likelihood environment is. In the next step we also want to sample the shape of the likelihood. We can either do this by a grid search as well, simply using $K>3$ grid points in each dimension. The number of grid points scales exponentially with $N$ and it might be, that some of the grid points have very low likelihood and we would waste time on calculating them anyway. In this case it could be a better idea to sample the likelihood (or rather the posterior probability distribution, which is the likelihood times some priors, cf. \S ????) using a Monte-Carlo Markov Chain (MCMC). Launching the walkers close to the already known peak could lead to a convergence of the MCMC in much less than $K^N$ likelihood evaluations.

[TO DO]
