\subsection{Model parameter estimates in the limit of large data sets} \label{sec:largedata}

The individual \MAP in \citet{bov13} contained typically between 100 and 800 objects, so that each \MAP implied a quite broad \pdf for the model parameters $\pmodel=\{p_\Phi,p_\text{DF}\}$. Here we explore what happens in the limit of very much larger samples for each \MAP, say 20,000 objects. As outlined in \S\ref{sec:likelihood} the immediate consequence of larger samples is given by the likelihood normalization requirement, $\log(1+{\mathrm rel. error})\le 1/N_{sample}$, (see Eq. \ref{eq:loglikelihood_relerr}), which is the modelling aspect that drives the computing time. This issues aside, we would, however, expect that in the limit of large data sets with vanishing measurement errors the \pdf s of the \pmodel become Gaussian, with a \pdf width (i.e. standard error SE of the Gaussian) that scales as $1/N_\text{sample}$. Further, we must verify that any bias in the \pdf expectation value is far less than SE, even for quite large samples.

Using sets of mock data, created according to \S\ref{sec:mockdata} and with our fiducial model for \pmodel in Table \ref{tbl:tests}, Tests \textcircled{2}, \textcircled{3} and \textcircled{10}, we verified that \RM satisfies all these conditions and expectations. Fig. \ref{fig:triangleplot} illustrates the joint \pdf `s of all \pmodel. This figure illustrates that the \pdf `s are multivariate Gaussians that project into Gaussians when considering the marginalized \pdf for all the individual \pmodel . Note that some of the parameters are quite covariant, but the level of their actual covariance depends on the choice of the \pmodel~ from with the mock data were drawn.  Figure\ref{fig:sqrtN} then illustrates that the \pdf~ width, SE, indeed scales as $1/N_\text{sample}$. Fig.\ref{fig:centrallimittheorem} illustrates even more, that \RM satisfies the central limit theorem. The average parameter estimates from many mock samples with identical underlying \pmodel are very close to the input \pmodel , and the distribution of the actual parameter estimates are a Gaussian around it. 

%====================================================================

%FIGURE: Triangle plot, shape of likelihood, multi-variate Gaussian

\begin{figure*}
\plotone{figs/isoSphFlex_short_hot_2kpc_triangle_MCMC.eps}
\caption{The likelihood in Eq. (\ref{eq:prob}) in the parameter space $\pmodel = \{p_\Phi,\ln(p_\text{DF})\}$ for one example mock data set created according to Test \textcircled{10} in Table \ref{tbl:tests}. Blue indicates the likelihood for the potential parameters, green the qDF parameters. The true parameters are marked by dotted lines. The dark, medium and bright contours in the 2D distributions represent 1, 2 and 3 sigma confidence regions, respectively, and show weak or moderate covariances. This analysis was picked among five similar analyses, to have all 1 sigma contours encompass the input values. The likelihood here was sampled using MCMC (with flat priors in $p_\Phi$ and  $\ln(p_\text{DF})$ to turn the likelihood into a full \pdf). Because only 10,000 MCMC samples were used to create the histograms shown, the 2D distribution has noisy contours. The dashed lines in the 1D distributions are Gaussian fits to the histogram of MCMC samples. This demonstrates very well that for such a large number of stars, the likelihood approaches the shape of a multi-variate Gaussian, as expected from the central limit theorem.}
\label{fig:triangleplot}
\end{figure*}

%====================================================================

%FIGURE: width of likelihood propto 1/sqrt(N)

\begin{figure}
\plotone{figs/sqrtNiso_Stddev_Vs_N.eps}
\caption{The width of the likelihood for two fit parameters found from analyses of 132 mock data sets vs. the number of stars in each data set. The mock data was created in the "Iso-Pot" potential and all model parameters are given as Test \textcircled{2} in Table \ref{tbl:tests}. The likelihood in Eq. \ref{eq:prob}  was evaluated on a grid and a Gaussian was fitted to the marginalized likelihoods of each free fit parameter. The standard error (SE) of these best fit Gaussians is shown for the potential parameter $b$ in kpc (red dots) and for the qDF parameter $\ln(h_R/8\text{kpc})$ in dimensionless units (blue). The black lines are fits of the functional form SE$(N_\text{sample}) \propto 1/\sqrt{N_\text{sample}}$ to the data points of both shown parameters. As can be seen, for large data samples the width of the likelihood behaves as expected and scales with $1/\sqrt{N_\text{sample}}$ as predicted by the central limit theorem.} 
\label{fig:sqrtN}
\end{figure}

%====================================================================


%FIGURE: central limit theorem is satisfied

\begin{figure*}
\plotone{figs/isoSph_CLT.eps}
\caption{(Un-)bias of the parameter estimate: According to the central limit theorem the likelihood will follow a Gaussian distribution for a large number of stars. From this follows that also for a large number of data sets the corresponding best fit values for the model parameters have to follow a Gaussian distribution, centered on the true model parameters. That our method satisfies this and is therefore an unbiased estimator [TO DO: can I say that????] is demonstrated here. We create 640 mock data sets. They come from two different "Iso-Pot" potentials (first and second column), two different stellar populations ("hot" \MAP (solid symbols) and "cool" \MAP (open symbols)) and five spherical observation volumes of different sizes (color coded, see legend). All model parameters are summarized in Table \ref{tbl:tests} as test \textcircled{3}. We determine the best fit value and the standard error (SE) for each fit parameter by fitting a Gaussian to the marginalized likelihood. The offset is the difference between the best fit and the true value of each model parameter. In the first two columns the offset in units of the SE is plotted vs. the SE in \% of the true model parameter. The first row shows the results for the isochrone scale length $b$ and the second row the qDF parameter $h_{\sigma_z}$, which corresponds to the scale length of the vertical velocity distribution. [TO DO: rename isochrone potential in title to "Iso-Pot".]}
\label{fig:centrallimittheorem}
\end{figure*}

\addtocounter{figure}{-1}
\begin{figure} [t!]
  \caption{(Continued.) The last column finally displays a histogram of the 640 offsets (in units of the corresponding SE). The black solid line is a Gaussian fit to a histogram. The dashed pink line is a normal distribution $\mathscr{N}(0,1)$. As they agree very well, our modelling method is therefore well-behaved and unbiased. For the 32 analyses belonging to one model we also determine the mean offset and SE, which are overplotted in black in the first two columns (with $1/\sqrt{32}$ as error).  [TO DO: Is the scatter of the black symbols too large??? Is the reason for this numerical inaccuracies???]} 
  \end{figure}

%====================================================================

