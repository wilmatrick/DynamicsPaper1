\section{Discussion and Summary}

We present \RM, an improved implementation of the dynamical modelling machinery by \citet{bov13}, to recover the potential and orbit distribution function of stellar \MAPs within the Galactic disk. In this work we investigated the capabilities, strengths and weaknesses of \RM by testing its robustness against the breakdown of some of its assumptions - for well defined, isolated test cases using mock data. Overall the method works very well and reliable, also if there are small deviations of the model assumptions from the real world galaxy.

\paragraph{Improved implementation.} Large data sets in the age of Gaia require more and more accurate likelihood evaluations for more flexible models. To be able to deal with these increased computational demands and explore larger parameter spaces, we sped up the code by combining a nested grid approach with MCMC and by faster action calculation using the St\"{a}ckel \citep{bin12} interpolation grid by \citet{bov15}. Especially accurately determining the likelihood normalisation will be of crucial importance for large data sets. The nested-grid approach automatizes the search for the optimal normalisation integration ranges ("fiducial qDF") and start position for the MCMC walkers, which helps the MCMC to converge fast and to reduce biases due to insufficient accuracy.

[TO DO]

\begin{itemize}

\item \textbf{Objective of this Paper in a Nutshell}
\begin{itemize}
\item 

--  nested grid to initialize MCMC: no need to set fiducial DF by hand <-- potential source of bias; speed-up; 
-- straighforward implementation of different potential families..
-- straighforward implementation of more potential/DF parameters, full 3D selection function (some symmetries) 
-- far higher accuracy --> needed for larger samples; better convergence.....


\end{itemize}

\item \textbf{Summary of Results - Machinery}

\begin{itemize}
\item Our fitting uses a full likelihood analysis, accounting for selection effects etc.
\item The method is an asymptotically normal un-biased estimator and precision of the parameter recovery increases by $1/\sqrt{N}$ with the number of stars.
\item Getting un-biased results also for very large data sets, requires us to calculate the normalisation with very high precision $\longrightarrow$ analysis of GAIA data will be a task for huge supercomputers and/or other ways to speed up the action calculation or the fitting routine have to be made.
\item This was not yet a problem for the small sample sizes in BR13. Improvements in RoadMapping to make it more adept for large data sets and more free parameters: Nested-grid search with MCMC combination.
\end{itemize}

\item \textbf{Summary of Results - Data}

\begin{itemize}
\item \emph{Survey volume position:} The position of the survey volume matters little i.e. there are no regions that are intrinsically manifestly more diagnostic than others. Only difference: closer to the disk \& bulge there are more stars.
\item \emph{Survey volume \& stellar population:} \MAPs of different scale length and temperature probe different regions of the Galaxy \citep{bov13}. However, there is no easy rule of thumb for which selection function and stellar population which potential and DF parameter is constrained best.
\item \emph{Survey volume shape:} [No definite result yet] A large coverage in both R and z however is best; in the axisymmetric case phi coverage doesn't matter. Making a volume cut for stars, that lie around $R_\odot$ but at larger $phi$, could therefore improve the results, if their measurements are very uncertain.

\item \emph{Incompleteness:} Surprisingly the method seems to be very robust against small to medium misjudgments in the incompleteness of the data. (We investigated a radial and a planar decrease in completeness while still assuming a complete data set.) This could be, because missing stars in the data set do not affect the connection between a star's velocity at a given position. A lot of information about the potential shape is stored in the rotation curve - but even when not including vT in the analysis, small misjudgments are not a deal breaker. This result is especially encouraging for future studies, because selection functions usually depend in a non-trivial, and often not perfectly known way on the observables.

\item \emph{Measurement errors:} Properly convolving the likelihood with measurement errors is computational very expensive. By ignoring positional errors and only including distance errors as part of the velocity error, we can drastically reduce the computational costs. [No definite result yet] For stars within 3 kpc from the sun this approximation works well for distance errors of $\sim 10\%$ or smaller. The number of MC samples to do the error convolution using MC integration scales by $N_\text{error} \propto (\sigma_{v,\text{max}})^2$ with the maximum velocity error at the edge of the sample.
\end{itemize}

\item \textbf{Summary of Results - Model}

\begin{itemize}
\item \emph{Distribution Function - MAPs not following qDF:} 
\begin{itemize}
\item \underline{Assumption to test:} Our modelling crucially depends on the assumption, that the Galactic disk consists of many \MAPs, each following a qDF. 
\item \underline{Test case:} In Example 1 in \S ??? we investigated how well we can recover the potential parameters, if this assumption was not perfectly satisfied, i.e. the \MAPs true DF does not perfectly follow a qDF. We consider two cases: a) a hot DF, that has less stars at small radii and more stars with low velocities than predicted by the qDF (reddish data sets in Fig. \ref{fig:isoSphFlexMix_mockdata}), or b) a cool DF that has broader velocity dispersion wings and less stars at large radii than predicted by the qDF (bluish data sets). 
\item \underline{Result:} We find that the former would give more reliable results for the potential parameter recovery.
\item \underline{Additional thought:} At the same time, if we assume that the distribution of stars from one \MAP is caused by radial migration away from the initial location of star formation, it is more likely that the qDF overestimates the true number of stars at smaller radii than underestimating it at larger radii. [TO DO: Is this actually a sensible argument???] 
\item \underline{Conclusion:} From this follows that focusing the analysis especially on hotter \MAPs could be an advisable way to go in the future, if there is doubt if the stars truly follow the qDF.
\end{itemize}

\item \emph{Distribution Function - MAPs polluted by neighbouring MAPs:} 
\begin{itemize} 
\item \underline{Assumption to test:} Another critical point is the binning of stars into \MAPs depending on their metallicity and $\alpha$ abundances. 
\item \underline{Test case:} Example 2 in \S ??? could be understood as a model scenario for decreasing bin sizes in the metallicity-$\alpha$ plane when sorting stars in different \MAPs, assuming that there is a smooth variation of qDF within the metallicity-$\alpha$ plane and each \MAP indeed follows a qDF. 
\item \underline{Result \& Conclusion:} We find that, in the case of 20,000 stars in each bin, differences of $20\%$ in the qDF parameters of two neighbouring bins can still give quite good constraints on the potential parameters. 
\item \underline{Comparison with BR13:} We compare this with the relative difference in the qDF parameters in the bins in Fig. 6 of \cite{bov13}, which have sizes of $[Fe/H] = 0.1$ dex and $\Delta [\alpha/Fe] = 0.05$ dex. It seems that these bin sizes are large enough to make sure that $\sigma_{R,0}$ and $\sigma_{z,0}$ of neighbouring \MAPs do not differ more than $20\%$. As fig. \ref{fig:isoSphFlexMixCont} and \ref{fig:isoSphFlexMixDiff} suggests especially the tracer scale length $h_R$ needs to be recovered to get the potential right. For this parameter however the bin sizes in fig. 6 of \cite{bov13} might not yet be small enough to ensure no more than $20\%$ of difference in neighbouring $h_R$, especially in the low-$\alpha$ ($[\alpha/Fe] \lesssim 0.2$), intermediate-metallicity ($[Fe/H] \sim -0.5$) \MAPs - provided of course, that each bin contains 20,000 stars. In case there are less than 20,000 stars in each bin the constraints are less tight and due to Poisson noise one could also allow larger differences in neighbouring \MAPs while still getting reliable results.
\item \underline{Additional throught:} Discussing Sanders \& Binney's doubts here?
\end{itemize}

\item \emph{Potential model misjudgment:} 
\begin{itemize} 
\item \underline{Assumption to test:} What happens if the true potential does not exactly belong to the familiy of fit potentials?
\item \underline{Test case:} Fitting 2-component Staeckel potential to bulge+halo+disk potential.
\item \underline{Result:} [Not a definite result yet.] Quite successful. Of course an exact reproduction is not possible, but the best fit potential is not much worse than a fit of the potential directly to the forces and rotation curve.  
\item \underline{Additional thought:} Using a Staeckel potential as potential model would have the advantage of fast and exact action calculations. Plus, the model can be made more flexible by adding additional Staeckel components (see e.g. Famaey \& Dejonghe 2003 ???), e.g. more disk components of another roundish component for the bulge. And the model potential family will always deviate from the true potential model, so using a flexible enough Staeckel has no disadvantages. Only problem: Disentangling the potential in distinct halo and disk etc. components would be more difficult.
\end{itemize}

\end{itemize}


\item \textbf{Other Action/DF-based modelling} Compare to our own approach

\begin{itemize}
\item \underline{Piffl et al. 2014:} They fitted a superposition of DFs (superposition of qDFs for cohorts in thin disk, single qDF for thick disk, other DF for halo) to the full RAVE data set. No chemical information at all. No treatment of selection function. Fitting of velocity dispersion histograms in density bins. Advantage: Avoiding problem of accurate normalisation calculation. Disadvantage: A lot of stellar information is not used.
\item  \underline{Sanders \& Binney 2015:} developed extended distribution functions, i.e. functions of both actions and metallicity for thin/thick disk + halo. Including of selection function. BUT: potential not fitted.
\item \underline{Ultimate goal:} Fitting both a very flexible distribution function in both action/abundance space for the whole galaxy + flexible potential.
\item \underline{Binney's group's focus:} rather on developing eDFs, potential recovery more secondary.
\item \underline{Our focus:} getting very good constraints on potential with an optimum of simplicity in DF and flexibility in capturing the actual distribution. 
\item \underline{Our philosophy:} We see our approach as intermediate/first step before ultimately using eDFs. We don't think that there is an easy to find and formulate eDF that describes the distribution of stars in both action and abundance space (metallicity AND alpha), see fig. 6 in Bovy \& Rix (2013). Bovy \& Rix 2013 were fitting each \MAP separately with a qDF and potential and used the best fit potential model only to give a mass constraint at one radius. By doing so they/we 
\begin{itemize}
\item[a)] separate out complexity / avoid explicitely dealing with the substructure of the DF in abundance space while still including abundance information (it's easier to see what goes right and wrong; less assumptions) 
\item[b)] make use of different \MAPs constraining different regions of the potential best and are therefore less limited by having to get the potential model right.
\item[c)] Quote HW: "It provides true cross-checking redundancy w.r.t. the potential estimates." [What does he mean by that?]
\end{itemize}
\end{itemize}

\item \textbf{On the assumption of axisymmetry} 
\begin{itemize}
\item \underline{Key assumption of the modelling:} axisymmetry of the MW. Needed for action calculation/conservation.
\item \underline{Reality:}  real disk has spiral arms and ring-like structures, with a warp and a flare in the outer disk. Also the Milky Way's halo has substructure, streams and shell-like overdensities. In the case of non-axisymmetry actions are not conserved anymore, so this could indeed affect the modelling.
\item \underline{Does modelling still work?} Has to be investigated in detail in future work, by trying to recover the potential in N-body simulations. Because actions are at least conserved under adiabatic chnages of the potential, and the vertical action under radial migration, there is some hope, that it could still work.
\item \underline{Intermediate step to Ultimate goal:} Ultimate goal: Finding substructures observationally and describing theoretically the structure and evolution of potential perturbations. Including non-axisymmetries also in modelling. Could be approached as applying perturbations to an equilibrium model - the axisymmetric model. 
\item \underline{Other applications:} a) Axisymmetric model also helps finding and explaining sub-structures.  b) As we are still far away from a completely realistic MW potential model, the axisymmetric case will be our reference to turn x,v into orbits, needed as tracers of Galaxy evolution.
\end{itemize}


\end{itemize}
